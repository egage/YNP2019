# Environmental Logger Data 2012 - 2018

**Updated: `r format(Sys.time(), '%Y %B %d')`**


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```


## Introduction

This section provides a basic interrogation of environmental measurement data archived on the "Digital Collections of Colorado" (DCC) library site and data collected in 2016-2018. These analyses are aimed at characterizing basic data structure and identifying potential issues such as:

* Inconsistently named factors such as site name or logger ID    
* Missing values  
* Data values outside of expected range or showing unusual patterns


```{r,echo=FALSE}

# library(here)
# here()
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(fs))
suppressPackageStartupMessages(library(sf))
suppressPackageStartupMessages(library(janitor))
suppressPackageStartupMessages(library(readxl))
suppressPackageStartupMessages(library(mapview))
# library(ggmap)
# library(ggrepel)
suppressPackageStartupMessages(library(viridis))
library(ggExtra)
library(DT)
suppressPackageStartupMessages(library(lubridate))
library(anytime)
# suppressPackageStartupMessages(library(compare))
suppressPackageStartupMessages(library(skimr)) ## some useful functions
suppressPackageStartupMessages(library(dataMaid))

```

## Soil Moisture data 



### 2012-2015 Data (DCC Collection)

### 2012-2015 (DCC Collection)

#### Data import and initial inspection 

### 2016 Data 

#### Data import and initial inspection 

EM50 dataloggers have a particualr output format. Need to cleave off several of the top rows.
Two tabs describe the raw sensor and processed data (e.g., VWC)
```{r, eval=FALSE}

# use 'readxls' functions
# read_excel(path, sheet = NULL, range = NULL, col_names = TRUE,
#   col_types = NULL, na = "", trim_ws = TRUE, skip = 0, n_max = Inf,
#   guess_max = min(1000, n_max))

#  Get the names and paths. 
list.files <- fs::dir_ls("data/raw/env_data_loggers",recurse = TRUE, glob = "*.xls")

## Purrr: take list and read in first sheet of each folder
env1 <- list.files %>%
  # map_df(read_excel, .id = "file", sheet = 1,skip = 2, col_types = c("text","date", "numeric", "numeric","numeric","numeric","numeric","numeric")) %>%
  map_df(read_excel, .id = "file", sheet = 1,skip = 2, col_types = "text") %>% # have to specify the "text" otherwise it fubars the guessing of data types with the date
  janitor::clean_names() 

```

```{r, eval=FALSE, echo=FALSE}
####
env1 %>% 
  # distinct(file) %>% 
  separate(col = file, into = c("A1","A2","A3"), sep = " ",fill = "right") %>% 
  head()
# data/raw/env_data_loggers/
```


```{r, eval=FALSE}
################# trying on a subset...
## just the august 17 folder. Trying to see if this helps...
list.files <- fs::dir_ls("data/raw/env_data_loggers/Aug 2017",recursive = TRUE, glob = "*.xls")

## Purrr: take list and read in first sheet of each folder
env1 <- list.files %>%
  # map_df(read_excel, .id = "file", sheet = 1,skip = 2, col_types = c("text","date", "numeric", "numeric","numeric","numeric","numeric","numeric")) %>%
  map_df(read_excel, .id = "file", sheet = 2,skip = 2) %>%
  # map_df(read_excel, .id = "file", sheet = 1,skip = 2, col_types = "text") %>% # have to specify the "text" otherwise it fubars the guessing of data types with the date
  janitor::clean_names() 

env1 <- env1 %>% 
  mutate_at(.vars = c(3:11),.funs = as.numeric) 


## fail. The x and y axes are crap....
env1 %>% 
  ggplot(aes(measurement_time,m³m³vwc)) +
  geom_line() +
  facet_wrap(~file)

# View(env1)
# 
# env1 %>% 
#   head() %>% 
#   mutate(m³m³vwc = as.numeric(m³m³vwc)) %>% 
#   mutate(x = excel_numeric_to_date(x,date_system = "modern",include_time = TRUE))


## This seems to work. But not in a mutate call for some reason
# excel_numeric_to_date(as.numeric(env1$measurement_time), date_system = "modern", include_time = TRUE)

# env1[["ExcelDateTime"]] <- excel_numeric_to_date(as.numeric(env1$measurement_time), date_system = "modern", include_time = TRUE)

# View(env1)

env1 %>%
  mutate(ddd = as.character(ExcelDateTime))
  head()
  
```



```{r, eval=FALSE}

######## scrap
env1 %>% 
  mutate(xxx = excel_numeric_to_date(as.numeric(measurement_time), date_system = "modern", include_time = TRUE))

env1 %>% 
  head() %>% 
  mutate(measurement_time = as.numeric(measurement_time)) %>%
  mutate(measurement_time = janitor::excel_numeric_to_date(measurement_time, date_system = "modern", include_time = TRUE))

env1 %>% 
  # distinct(file) %>% 
  separate(file, into = c("pa","pb","pc","pd","file.name"), sep = "/" ) %>%
  select(-c(pa, pb, pc, pd)) %>% 
  View()


###### this ain't working
env_list <- list.files %>%
  map(read_excel, .id = "file", sheet = 1,skip = 2, col_types = "text") %>% 
  janitor::clean_names() 

```



```{r, eval=FALSE}
##################### EXAMPLE #################################
# Read a collection of files into one data frame.
# 
# dir_ls() returns a named vector, so it can be used directly with purrr::map_df(.id).

# Create separate files for each species
iris %>%
  split(.$Species) %>%
  map(select, -Species) %>%
  iwalk(~ write_tsv(.x, paste0(.y, ".tsv")))

# Show the files
iris_files <- dir_ls(glob = "*.tsv")
iris_files
#> setosa.tsv     versicolor.tsv virginica.tsv


# Read the data into a single table, including the filenames
iris_files %>%
  map_df(read_tsv, .id = "file", col_types = cols(), n_max = 2)

file_delete(iris_files)

```


### 2017 Data 
#### Data import and initial inspection 


### 2018 Data 
#### Data import and initial inspection 

### Clean and Combine Years

### Export Archivable Version of Cleaned Data for Further Analysis 


## Air Temperatures 
### 2012-2015 Data (DCC Collection)

#### Data import and initial inspection 


### 2016 Data 
#### Data import and initial inspection 

### 2017 Data 
#### Data import and initial inspection 


### 2018 Data 
#### Data import and initial inspection 

### Clean and Combine Years

### Export Archivable Version of Cleaned Data for Further Analysis