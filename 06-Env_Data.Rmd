---
output: 
  html_document: 
    theme: readable
---
# Environmental Logger Data 2012 - 2019

**Updated: `r format(Sys.time(), '%Y %B %d')`**


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

```


## Introduction

This section provides a basic interrogation of environmental measurement data archived on the "Digital Collections of Colorado" (DCC) library site and data collected in 2016-2018. These analyses are aimed at characterizing basic data structure and identifying potential issues such as:

* Inconsistently named factors such as site name or logger ID    
* Missing values  
* Data values outside of expected range or showing unusual patterns


```{r,echo=FALSE}

# library(here)
# here()
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(fs))
suppressPackageStartupMessages(library(sf))
suppressPackageStartupMessages(library(janitor))
suppressPackageStartupMessages(library(readxl))
suppressPackageStartupMessages(library(mapview))
# library(ggmap)
# library(ggrepel)
suppressPackageStartupMessages(library(viridis))
library(ggExtra)
library(DT)
suppressPackageStartupMessages(library(lubridate))
library(anytime)
# suppressPackageStartupMessages(library(compare))
suppressPackageStartupMessages(library(skimr)) ## some useful functions
suppressPackageStartupMessages(library(dataMaid))
library(visdat)
library(gt)
library(tsibble) ## ts
library(feasts) ## ts

```

## Soil Moisture data 

```{r}
### 2012-2015 Data (DCC Collection)

### 2012-2015 (DCC Collection)

#### Data import and initial inspection 

### 2016 Data 

#### Data import and initial inspection 
```


EM50 dataloggers have a particular output format. Need to cleave off several of the top rows.
Two tabs describe the raw sensor and processed data (e.g., VWC)

```{r, eval=TRUE}

# use 'readxls' functions
# read_excel(path, sheet = NULL, range = NULL, col_names = TRUE,
#   col_types = NULL, na = "", trim_ws = TRUE, skip = 0, n_max = Inf,
#   guess_max = min(1000, n_max))

#  Get the names and paths. 
list.files <- fs::dir_ls("data/raw/env_data_loggers",recurse = TRUE, glob = "*.xls")

## Purrr: take list and read in first sheet of each folder
env1 <- list.files %>%
  # map_df(read_excel, .id = "file", sheet = 1,skip = 2, col_types = c("text","date", "numeric", "numeric","numeric","numeric","numeric","numeric")) %>%
  map_df(read_excel, .id = "file", sheet = 1,skip = 2, col_types = "text") %>% # have to specify the "text" otherwise it fubars the guessing of data types with the date
  janitor::clean_names() 

```
# >
```{r}
env1 %>% 
  distinct(file) %>% 
  datatable(caption = "Distinct decagon logger files to merge")
```

**158 distinct logger files to deal with...**

```{r, eval=TRUE, echo=TRUE}

####
env1 <- env1 %>% 
  mutate(date = excel_numeric_to_date(as.numeric(as.character(measurement_time)), date_system = "modern"))  %>%
  mutate(yr = as.integer(year(date))) %>% 
  mutate_at(vars(contains("temp")), as.numeric) %>% 
  mutate_at(vars(contains("vwc")), as.numeric) %>% 
  mutate(mm_precip = as.numeric(mm_precip)) %>% 
  mutate_if(is.character, tolower) %>% 
  select(-contains("none"))

env1 %>% 
  sample_n(10000) %>% 
  vis_dat()

env1 %>% 
  distinct(file) %>% datatable()

```

```{r}
# split 
env1 <- env1 %>% 
  separate(col = file, into = c("a1","a2","a3","a4","a5"), sep = "/",fill = "right", remove = FALSE) %>% 
  select(-c(a1,a2,a3,a4)) %>%
  # str_split(fruits, " and ")
  mutate(file_n = str_remove(string = a5,pattern = ".xls")) 

env1 <- env1 %>%
  filter(!str_detect(file_n, "Arch")) %>% #filter out the "archived" files
  mutate(file_n = str_replace(string = file_n,pattern = "-",replacement = " ")) %>% 
  mutate(file_n = str_replace(string = file_n,pattern = "-",replacement = " ")) %>% 
  # View()
  # distinct(file_n) %>% datatable()
  separate(col = file_n, into = c("site","datep","logger_info"),sep = " ",remove = FALSE) 


env1 %>%
  separate(col = logger_info, into = c("dloadd","logger_id"),sep = "-",remove = FALSE) 

```

```{r}
## join in site plot info

# env1 %>% 
#   distinct(site) %>% 
#   write_csv("./data/lu_em50_site_plot.csv")

lu.em50 <- read_csv("./data/lu_em50_site_plot.csv")

##
env1 <- env1 %>% 
  left_join(.,lu.em50,by='site') %>% 
  mutate(site = site2) %>% 
  select(-site2)

env1 <- env1 %>% 
  select(-contains('none')) %>% 
  select(-c(a5))



```

```{r}

env1 %>% 
  tabyl(site,plot) %>% 
  gt() 


```

no eb1 dc!

```{r}
env1 %>% 
  sample_n(10000) %>% 
  vis_dat()

```

```{r}

env1 %>% 
  tabyl(site, yr) %>% datatable(caption = "issues with date parsing at 'Rose'")

env1 %>% 
  tabyl(logger_id, yr) %>% datatable(caption = "issues with date parsing at 'Rose'")


#### excel time fix
env1 <- env1 %>% 
  mutate(measurement_time = as.numeric(measurement_time)) %>%
  mutate(measurement_time = janitor::excel_numeric_to_date(measurement_time, date_system = "modern", include_time = TRUE)) %>% 
  mutate(doy = yday())

env1 <- env1 %>% 
  mutate(month = lubridate::month(measurement_time)) %>% 
  mutate(hour = hour(measurement_time)) 

env1 %>%
  select(measurement_time) %>% 
  head() %>% gt()

```

```{r}
env1 %>% 
  filter(plot != "obs") %>% 
  ggpl

```


```{r, eval=FALSE}
################# trying on a subset...
## just the august 17 folder. Trying to see if this helps...
list.files <- fs::dir_ls("data/raw/env_data_loggers/Aug 2017",recursive = TRUE, glob = "*.xls")

## Purrr: take list and read in first sheet of each folder
env1 <- list.files %>%
  # map_df(read_excel, .id = "file", sheet = 1,skip = 2, col_types = c("text","date", "numeric", "numeric","numeric","numeric","numeric","numeric")) %>%
  map_df(read_excel, .id = "file", sheet = 2,skip = 2) %>%
  # map_df(read_excel, .id = "file", sheet = 1,skip = 2, col_types = "text") %>% # have to specify the "text" otherwise it fubars the guessing of data types with the date
  janitor::clean_names() 

env1 <- env1 %>% 
  mutate_at(.vars = c(3:11),.funs = as.numeric) 



env1 %>% 
  ggplot(aes(measurement_time,m³m³vwc)) +
  geom_line() +
  facet_wrap(~file)

#env1 <- env1 %>%
  mutate(measurement_time = as.numeric(measurement_time)) %>%
  mutate(measurement_time = janitor::excel_numeric_to_date(measurement_time, date_system = "modern", include_time = TRUE))

```

```{r}
# install.packages("tsibble")
# library(tsibble)



```


### Clean and Combine Years

### Export Archivable Version of Cleaned Data for Further Analysis 


#